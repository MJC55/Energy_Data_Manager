{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V1O82nvuz-2V",
        "HY00M26_Xkdp",
        "0enjBxFQCepQ"
      ],
      "mount_file_id": "1WcANLGQ7S4R4IICW28COhYlBlSnNghbZ",
      "authorship_tag": "ABX9TyMR7kxCnDI0NcZ/6uC8O8hZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJC55/Energy_Data_Manager/blob/master/OCR_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1O82nvuz-2V"
      },
      "source": [
        "# Import Files and Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n91U4bs3vAN"
      },
      "source": [
        "#https://www.youtube.com/watch?v=glJi3LBgn9U"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LUxtzS6nSvF"
      },
      "source": [
        "!apt-get install ocrmypdf -q\n",
        "#   Package version incompatible with Python 3, easy fix is to \n",
        "#/usr/lib/python3/dist-packages/ruffus/task.py\n",
        "#   1) delete line 715 and \n",
        "#   2) comment out line 5944"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98-OsFisnSxI"
      },
      "source": [
        "!pip install pdfplumber -q\n",
        "!pip install tabula-py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfGEzjwnuAIj",
        "outputId": "51493d57-8baa-480a-e921-8521eaeca98d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNlgbxiznSzS"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import pdfplumber\n",
        "import tabula\n",
        "from google.colab import files #https://stackoverflow.com/questions/49394737/exporting-data-from-google-colab-to-local-machine\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkamWMI0eUZo"
      },
      "source": [
        "#Import local files\n",
        "##############################################################3\n",
        "from google.colab import files\n",
        "def getLocalFiles():\n",
        "    _files = files.upload()\n",
        "    if len(_files) >0:\n",
        "       for k,v in _files.items():\n",
        "         open(k,'wb').write(v)\n",
        "getLocalFiles()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1P1VTNy1-ea"
      },
      "source": [
        "#Interesting Notes or articles\n",
        "#Image rectification https://medium.com/cashify-engineering/improve-accuracy-of-ocr-using-image-preprocessing-8df29ec3a033\n",
        "#OCRmyPDF https://www.youtube.com/watch?v=glJi3LBgn9U\n",
        "#clean and centralize image https://stackoverflow.com/questions/41995916/opencv-straighten-an-image-with-python\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY00M26_Xkdp"
      },
      "source": [
        "# OLD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2ST6Ta7ntY0"
      },
      "source": [
        "#OLD code for function to get pdf from online source\n",
        "def download_file(url):\n",
        "    local_filename = url.split('/')[-1]\n",
        "    \n",
        "    with requests.get(url) as r:\n",
        "        assert r.status_code == 200, f'error, status code is {r.status_code}'\n",
        "        with open(local_filename, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "        \n",
        "    return local_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp6byvOxnS1W"
      },
      "source": [
        "invoice = 'https://bit.ly/2UJgUpO'\n",
        "invoice_pdf = download_file(invoice)\n",
        "\n",
        "invoice_pdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4NPNKeA1Lft"
      },
      "source": [
        "#Initialize the output textfile\n",
        "#######################################################################\n",
        "outfile = \"out_text.txt\" #define filename to write text\n",
        "#Remove text from previous runs\n",
        "e = open(outfile, 'a+') #https://stackoverflow.com/questions/1466000/difference-between-modes-a-a-w-w-and-r-in-built-in-open-function\n",
        "e.truncate(0) #https://stackoverflow.com/questions/2769061/how-to-erase-the-file-contents-of-text-file-in-python\n",
        "e.close() # need '0' when using r+"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmADDZTCjnc4"
      },
      "source": [
        "# **OCR the PDF file**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FhEAp1d14Rc"
      },
      "source": [
        "#Not yet found a way to a pass a variable for the filename\n",
        "\n",
        "#pdf_file=\"/content/PCE_Fuel.pdf\"\n",
        "#gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile=\"Power Cost Memorandum Fuel Cost Update.pdf\" \"Power Cost Memorandum Fuel Cost Update.pdf\"\n",
        "#     /content/PCE_Annual.pdf\n",
        "#     /content/PCE_Fuell.pdf\n",
        "!ocrmypdf Beaver_Fuel_3.pdf output_Fuel_2.pdf #--force-ocr should be added after ocrmypdf command\n",
        "\n",
        "print(' OCR Complete')\n",
        "#\"/PCE Annual Report.pdf\"\n",
        "#\"/Power Cost Memorandum Fuel Cost Update.pdf\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "AjpuZVIsfznA",
        "outputId": "857d210b-a7ec-4825-fa4e-2b656e14c19f"
      },
      "source": [
        "files.download('/content/output_Fuel_2.pdf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bdd16cdb-3791-41e0-bcd5-aad42de34090\", \"output_Fuel_2.pdf\", 4290309)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv7P5pqICHja"
      },
      "source": [
        "List of Files in Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNzBv6v90RCy"
      },
      "source": [
        "#Define List of Files\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/ACEP: Energy Data Manager/1 Alaska Energy Statistics/Test_RCA_Files\")\n",
        "File_list= os.listdir()\n",
        "print(File_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGKKXWLTCK4j"
      },
      "source": [
        "# Main Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3dUX0gumpIU"
      },
      "source": [
        "#Test Tabula-py\n",
        "#Tabula Links:\n",
        "# Jupyter example case for tabula https://nbviewer.org/github/chezou/tabula-py/blob/master/examples/tabula_example.ipynb\n",
        "# area parameter   https://stackoverflow.com/questions/45457054/tabula-extract-tables-by-area-coordinates\n",
        "# Data to numeric, DataFrame     https://towardsdatascience.com/converting-data-to-a-numeric-type-in-pandas-db9415caab0b\n",
        "\n",
        "for i in File_list:\n",
        "  #print(i)\n",
        "  #Tabulate pdf to dataframe\n",
        "  #print(i) #File_list[0]\n",
        "  print('---------------------------')\n",
        "  try:\n",
        "    App_1_page, App_2_page, Report = Find_Page(i) \n",
        "\n",
        "    #App1\n",
        "    df = tabula.read_pdf(str(i), pages=(str(App_1_page))) #  \"Kotzebue_Annual.pdf\" #Page es exact same as corrected output from searchpage\n",
        "    #print(df)\n",
        "    df=pd.DataFrame(df[0])\n",
        "    #print('Tabula-Read Complete')\n",
        "    ## Save output dataframe to csv with same name as pdf file that was tabulated to dataframe\n",
        "    File_2 = i[0:-4]\n",
        "    File_2 = str(File_2)+\"_\"+str(Report)+\"_App_1.csv\"\n",
        "    df.to_csv(str(File_2))\n",
        "\n",
        "    #App2\n",
        "    df = tabula.read_pdf(str(i), pages=(str(App_2_page))) #  \"Kotzebue_Annual.pdf\" #Page es exact same as corrected output from searchpage\n",
        "    #print(df)\n",
        "    df=pd.DataFrame(df[0])\n",
        "    #print('Tabula-Read Complete')\n",
        "    ## Save output dataframe to csv with same name as pdf file that was tabulated to dataframe\n",
        "    File_2 = i[0:-4]\n",
        "    File_2 = str(File_2)+\"_\"+str(Report)+\"_App_2.csv\"\n",
        "    df.to_csv(str(File_2))\n",
        "    print(\"File \"+str(File_2)+\" saved\")\n",
        "\n",
        "\n",
        "  except Exception as e: #if no Appendix is found and error message is given from Find_Page function\n",
        "    print('XXXXXXXX ERROR raised XXXXXXXXXX')\n",
        "    print(str(e))\n",
        "    pass\n",
        "  print('---------------------------')\n",
        "\n",
        "  #What still needs to be added:\n",
        "\n",
        "  ### Cleaning the generated DF\n",
        "    ### can vary between text recognizion and table recognition for indices and table content\n",
        "\n",
        "  ### Write validation steps into tracker csv (separate from main excel overview from Brenda due to size)\n",
        "    ### Track the Appendix finder, with 'complete' and 'pages'\n",
        "    ### Track the Report Type\n",
        "    ### Track the tabulation process into a DF... how to?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sddUn5jyH4Tn"
      },
      "source": [
        "# Ideas\n",
        "## Cleaning the generated DF\n",
        "can vary between text recognizion and table recognition for indices and table content\n",
        "\n",
        "## Write validation steps into tracker csv (separate from main excel overview from Brenda due to size)\n",
        "Track the Appendix finder, with 'complete' and 'pages'\n",
        "Track the Report Type\n",
        "Track the tabulation process into a DF... how to?\n",
        "\n",
        "#Code\n",
        "PDF redactor\n",
        "https://github.com/JoshData/pdf-redactor/blob/primary/example.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0enjBxFQCepQ"
      },
      "source": [
        "# Clean DF output  (testing phase)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgKxxzPAwMib"
      },
      "source": [
        "df_2=df.copy()\n",
        "columns=df.columns\n",
        "print(columns)\n",
        "df_2=df_2.dropna(subset=[str((columns[-1]))]   ) #drop rows that are NaN in last column\n",
        "#drop columns where most values are na\n",
        "df_2.columns\n",
        "#print(df)\n",
        "i=0\n",
        "while i<len(df_2.columns):\n",
        "  #i\n",
        "  print('new')\n",
        "  print(i)\n",
        "  print(df_2.columns[i])\n",
        "  col=df_2.columns[i]\n",
        "  df_2[str(col)] = df_2[str(col)].str.replace(',','')\n",
        "  df_2[str(col)] = df_2[str(col)].str.replace('$','')\n",
        "  df_2[str(col)] = df_2[str(col)].str.replace('%','')\n",
        "  df_2[str(col)] = df_2[str(col)].str.replace(';','')\n",
        "  number_of_nans=(df_2[str(col)].isnull().sum())\n",
        "  number_of_rows= len(df_2[str(col)])\n",
        "  if number_of_nans/number_of_rows>0.5: #drop column if most values are NaN\n",
        "    df_2=df_2.drop(columns=[str(col)])\n",
        "    print(\"Column \"+str(col)+' dropped')\n",
        "    print(i)\n",
        "    i-=1 #adjust counter, since there is one less column\n",
        "    print(i)\n",
        "  i+=1\n",
        "\n",
        "\n",
        "#df.apply(lambda x: x.str.replace('%',''))\n",
        "#df.apply(lambda x: x.str.replace(',',''))\n",
        "#Split first column by period\n",
        "#df.insert([0,1],'hey'df['Unnamed: 0'])\n",
        "a=df_2[str(df_2.columns[0])].str.split('.',expand=True)\n",
        "df_2=pd.concat([a,df_2.drop(columns=df_2.columns[0])],axis=1)\n",
        "df_2\n",
        "#df =df.reindex\n",
        "#df.str.find('Line')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "MeWZAn7OwGBQ",
        "outputId": "8ad783aa-5886-4db4-8edf-8c9a62ce6d5d"
      },
      "source": [
        "#df1[['V']] = pd.DataFrame([ x.split('-') for x in df['V'].tolist() ])\n",
        "df_2.to_csv('output_Fuel_2.csv',index=False) \n",
        "files.download('output_Fuel_2.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5a134354-14f3-4728-b391-d55183f05480\", \"output_Fuel_2.csv\", 665)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtRo4YmuCS3e"
      },
      "source": [
        "# Function to find Appendix Page (complete)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xx11mrYnS6C"
      },
      "source": [
        "########\n",
        "#Find the Appendix pages\n",
        "########\n",
        "\n",
        "\n",
        "#del App_1_found\n",
        "#del App_2_found\n",
        "#del App_1_index\n",
        "#del App_2_index\n",
        "\n",
        "def Find_Page(File_name):\n",
        "  print('Beginning Page Search for ' +str(File_name))\n",
        "  with pdfplumber.open(str(File_name)) as pdf:\n",
        "    print(pdf.pages) #number of pages\n",
        "    App_1_found=False\n",
        "    App_2_found=False\n",
        "    # Look for appendix in text\n",
        "    Report=\"Weeeeeird_Case_Reference_not_assigned\" #Initialize Variable\n",
        "    for i in range(len(pdf.pages)):\n",
        "      #print(pdf.pages[i])\n",
        "      page = pdf.pages[i]#[0]\n",
        "      #print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
        "      #print(i)\n",
        "      text = page.extract_text()\n",
        "      #print(text)\n",
        "      if 'Appendix 1' in text and ('PERIOD' in text or 'Period' in text) and 'POWER COST EQUALIZATION CAL' in text:\n",
        "        App_1=page\n",
        "        App_1_index=i\n",
        "        if App_1_found:\n",
        "          raise Exception('Appendix 1 recognized on multiple pages, should only be on one page') \n",
        "        App_1_found=True\n",
        "        #Check what kind of report it is, fuel report or annual report? Only if Appendix found, though\n",
        "        if \"Annual Update\" in text or \"ANNUAL UPDATE\" in text:\n",
        "          Report_1=\"Annual\"\n",
        "        elif \"Fuel Cost Update\" in text or \"FUEL COST UPDATE\" in text:\n",
        "          Report_1=\"Fuel\"\n",
        "        else:\n",
        "          Report_1=\"Weird_Case_Reference_not_assigned\"\n",
        "        print(Report_1)\n",
        "        print('Appendix 1 found and is page '+str(page))\n",
        "      if 'Appendix 2' in text and ('PERIOD' in text or 'Period' in text) and 'COSTS,' in text:\n",
        "        App_2=page\n",
        "        App_2_index=i\n",
        "        if App_2_found:\n",
        "          raise Exception('Appendix 2 recognized on multiple pages, should only be on one page') \n",
        "        App_2_found=True\n",
        "        #Check what kind of report it is, fuel report or annual report?\n",
        "        if \"Annual Update\" in text or \"ANNUAL UPDATE\" in text:\n",
        "          Report_2=\"Annual\"\n",
        "          if Report_1==\"Fuel\":\n",
        "            Report='Unclear'\n",
        "          else:\n",
        "            Report=\"Annual\"\n",
        "        elif \"Fuel Cost Update\" in text or \"FUEL COST UPDATE\" in text:\n",
        "          Report_2=\"Fuel\"\n",
        "          if Report_1==\"Annual\":\n",
        "            Report='Unclear'\n",
        "          else:\n",
        "            Report=\"Fuel\"\n",
        "        else:\n",
        "          Report='Nothing_found'\n",
        "        print(Report)\n",
        "        print('Appendix 2 found and is page '+str(page))\n",
        "      elif App_1_found: #if Appendix 2 is not found AND Appendix 1 IS found\n",
        "        Report=Report_1\n",
        "    if not App_1_found and App_2_found: #If App2 is found, but App1 isn't\n",
        "      App_1_index=App_2_index-1\n",
        "    if not App_2_found and App_1_found: #if App1 is found, but App2 isn't\n",
        "      App_2_index=App_1_index+1\n",
        "    if not App_1_found and not App_2_found:\n",
        "      raise Exception('Neither Appendix found in text, need manual entry') \n",
        "    App_1_text=pdf.pages[App_1_index].extract_text()\n",
        "    App_2_text=pdf.pages[App_2_index].extract_text()\n",
        "    print('Appendix 1 is page: '+str(App_1_index+1))\n",
        "    print('Appendix 2 is page: '+str(App_2_index+1))\n",
        "\n",
        "    print('Page Search successful')\n",
        "    print(Report)\n",
        "    return((App_1_index+1),(App_2_index+1),Report) #\"+1\" is added because of the intrinsic Python index, first page is not 0 but 1!\n",
        "\n",
        "    #page = pdf.pages[App_1_index]#[0]\n",
        "    #text = page.extract_text()\n",
        "    #print(text)\n",
        "    #print(page)\n",
        "    #f.write(text)\n",
        "    #print(App_1_text)\n",
        "    #print('------------------------------------------------------')\n",
        "    #print(App_2_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6tOWhziCZjA"
      },
      "source": [
        "# Old text analysis test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJES3RE6n2Gl"
      },
      "source": [
        "lines=text.split('\\n')\n",
        "lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b_fTP2_n2Ez"
      },
      "source": [
        "#Remove the unnecessary text content\n",
        "import re\n",
        "amt_re =re.compile(r'\\.\\d\\d\\d\\d') #lines with period with four numbers after it\n",
        "f = open(outfile, \"a\")\n",
        "for line in lines:\n",
        "  for c in ascii_letters: #replace all alphabetic values with \"\"\n",
        "    line = line.replace(c, '')\n",
        "  line = line.replace(',', '.')\n",
        "  print('hey')\n",
        "  print(line)\n",
        "  #line=re.sub(r\"^\\.\\d{4}\",\"\",line)\n",
        "    #line=re.sub(r'(?:([^\\s$$.\\d\\d\\d\\d])(?!.*\\1))+$','',line)\n",
        "    #hello=re.compile(r'(\\b\\s$$\\.\\d{4}\\b)').findall(line) #\\b\\s$$\\.\\d{4}\\b]\n",
        "    #print(hello)\n",
        "  hello=re.findall(r\"\\$\\d\\.\\d{4}\",line)\n",
        "  f.write(hello)\n",
        "  print(hello)\n",
        "    \n",
        "  if amt_re.search(line):\n",
        "    #print('hey')\n",
        "    f.write(line) #write to f (text file)\n",
        "    f.write('\\n')\n",
        "    print(line)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkga29j_n2CJ",
        "outputId": "94f067b5-5e4c-43b4-ebc7-888f83127307"
      },
      "source": [
        "from string import ascii_letters\n",
        "for line in lines:\n",
        "  for c in ascii_letters:\n",
        "    line = line.replace(c, '') \n",
        "  print(line)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  , 110. \n",
            "    \n",
            "    31, 2020 \n",
            "  \n",
            "91-0517  91·0521 \n",
            " \n",
            "      \n",
            "    . \n",
            "   / ( 2)  $0.3431)  $0.3630  $0;3443 \n",
            ".   / {) \n",
            "  -   $0.1427  $0.1627  $0.1440 \n",
            ".    ()  79.97 /  $0.1427  $0.1627  $0,1440 \n",
            ".     \n",
            "   \n",
            "  $0.1602  $0.1602  $0.1602 \n",
            "  \n",
            " /   $0.1771  $0,1771  $0.1771 \n",
            "-.  $0.2628  $0,2628  $0.2628 \n",
            " \n",
            "63   $0,2296  $0.2296  $0.2296 \n",
            "    \n",
            "   \n",
            ".   : ()  95%  () \n",
            "   \n",
            "  $0,1355  $0.1545  $0.1368 \n",
            "  \n",
            " /..  $0.1355  $0.1545  $0,1368 \n",
            "-.  $0.1355  $0.1545  $0.1368 \n",
            "  \n",
            "63   $0.1355  $0.1545  $0.1368 \n",
            ".       0%*  0%  0% \n",
            "   \n",
            "  $0.0000  $0.0000  $0.0000 \n",
            "  \n",
            " /..  $0.0000  $0.0000  $0.0000 \n",
            "-.  $0.0000  $0.0000  $0.0000 \n",
            "   &3   $0.0000  $0.0000  $0.0000 \n",
            "• -21-019(3),   22, 2021,      00.00 /,  \n",
            "      1, 2021. \n",
            "91•0521 \n",
            " 1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37UBB_N0n1_V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKJRQx9Vn18h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jCfqnFDn15n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}